# Gerekli kÃ¼tÃ¼phanelerin iÃ§e aktarÄ±mÄ±
import os
import json
from dotenv import load_dotenv
from langchain_core.documents import Document
from langchain.chains import create_retrieval_chain
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI


# Kitap verilerini iÅŸleyip RAG formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼ren fonksiyon
def data_preprocessing(data_path):
    with open(data_path, "r", encoding="utf-8") as f:
        books = json.load(f)

    rag_formatted = []

    for book in books:
        # Kitap bilgilerini tek bir string olarak birleÅŸtir
        content = (
            f"{book['title']} - {book['genre']} tÃ¼rÃ¼nde bir kitaptÄ±r, {book['author']} tarafÄ±ndan yazÄ±lmÄ±ÅŸtÄ±r. {book['summary']}"
            f"{book['price']} TL. Stok: {book['stock']} adet."
        )
        
        # Metadata bilgileri
        metadata = {
            "id": book["id"],
            "kitap_adi": book["title"].lower(),
            "yazar": book["author"].lower(),
            "tur": book["genre"].lower(),
            "fiyat": book["price"],
            "stok": book["stock"],
        }
        
        # LangChain Document objesi olarak ekle
        rag_formatted.append(Document(page_content=content, metadata=metadata))
    
    # Metni parÃ§alara ayÄ±r (chunk) - daha verimli vektÃ¶rleme iÃ§in
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    docs = text_splitter.split_documents(rag_formatted)   

    return docs


# Chatbot sÄ±nÄ±fÄ±
class Chatbot:
    def __init__(self):
        # .env dosyasÄ±ndaki API anahtarlarÄ±nÄ± yÃ¼kle
        load_dotenv(override=True)

        # Google Generative AI embedding modeli
        self.embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", api_key=os.getenv("GOOGLE_API_KEY"))
        
        # VektÃ¶r veritabanÄ±nÄ± yÃ¼kle
        self.upload_vectorstore("./chroma_books_db")

        # Benzerlik tabanlÄ± retriever ayarla
        self.retriever = self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 10}
        )

        # Gemini LLM modeli (dÃ¼ÅŸÃ¼k gecikmeli)
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash",
            temperature=0.3,
            max_tokens=500,
        )

        # Sistem promptu: LLM'e gÃ¶revini anlatÄ±r
        self.system_prompt = (
            "Sen bir kitapÃ§Ä± asistanÄ±sÄ±n. KullanÄ±cÄ±lara veritabanÄ±nda bulunan kitaplara gÃ¶re kitap tavsiyesi yapar, "
            "kitaplar hakkÄ±nda bilgi verir, yazar ve tÃ¼r bilgisi sunar, ayrÄ±ca stok ve fiyat bilgilerini paylaÅŸÄ±rsÄ±n. "
            "EÄŸer kullanÄ±cÄ± bir kitap hakkÄ±nda bilgi isterse Ã¶zetini ver, eÄŸer yazar sorarsa kitaplarÄ±nÄ± listele. "
            "KullanÄ±cÄ± belirli bir tÃ¼rde kitap isterse o tÃ¼rdeki kitaplarÄ± Ã¶ner."
            "'Sepet Ä°ÅŸlemi' olarak adlandÄ±rÄ±lan iÅŸlemlerde sadece kitap adÄ±nÄ± geri dÃ¶ndÃ¼r."
            "EÄŸer sepet iÅŸlemleriyle alakalÄ± bir durum varsa 'kitap_ekle', 'sepet_goster', 'sepet_temizle', 'sepet_toplam' ve 'kitap_cikar' intentlerinden uygun olanÄ± dÃ¶ndÃ¼r  "
            "EÄŸer sepet iÅŸlemi yapÄ±lÄ±yorsa hiÃ§bir aÃ§Ä±klama olmadan intent-kitap_ismi ÅŸeklinde dÃ¶nmeli "
            "VeritabanÄ±nda olmayan bilgi sorulursa nazikÃ§e bunu belirt.\n\n"
            "{context}"
        )

        # Prompt ÅŸablonu (sistem + kullanÄ±cÄ± mesajÄ±)
        self.prompt_template = ChatPromptTemplate.from_messages([
            ("system", self.system_prompt),
            ("human", "{input}")
        ])

        # Sepet baÅŸlangÄ±Ã§ta boÅŸ
        self.cart = []
    
    # VektÃ¶r veritabanÄ±nÄ± yÃ¼kleme veya oluÅŸturma
    def upload_vectorstore(self, persist_dir):
        if os.path.exists(persist_dir) and os.path.exists(os.path.join(persist_dir, "index")):
            # Var olan veritabanÄ±nÄ± yÃ¼kle
            self.vectorstore = Chroma(
                persist_directory=persist_dir,
                embedding=self.embeddings
            )
        else:
            # Yeni veritabanÄ± oluÅŸtur
            self.docs = data_preprocessing("kitaplar_dataset.json")
            self.vectorstore = Chroma.from_documents(
                documents=self.docs,
                embedding=self.embeddings,
                persist_directory=persist_dir
            )
    
    
    # Kitap sepete ekle
    def add_book(self, book):
        book = book.lower()
        found = [
            doc for doc in self.retriever.invoke(book)
            if book in doc.metadata.get("kitap_adi", "").lower()
        ]
        if found:
            self.cart.append(found[0].metadata)
            return f"âœ… '{found[0].metadata['kitap_adi']}' sepete eklendi."
        else:
            return f"âŒ '{book}' adlÄ± kitap bulunamadÄ±."
        
    # KitabÄ± sepetten Ã§Ä±kar
    def delete_book(self, book):
        book = book.lower()
        silindi = False
        for item in self.cart:
            if book in item["kitap_adi"].lower():
                self.cart.remove(item)
                return f"âŒ '{item['kitap_adi']}' sepetten Ã§Ä±karÄ±ldÄ±."
                silindi = True
                break
        if not silindi:
            return f"ğŸ” '{book}' adlÄ± kitap sepette bulunamadÄ±."
        
    # Sepeti gÃ¶ster
    def show_cart(self):
        if not self.cart:
            return "ğŸ›’ Sepet boÅŸ."
        else:
            mesajlar = ["ğŸ“¦ Sepetteki Kitaplar:"]
            for i, item in enumerate(self.cart, 1):
                mesajlar.append(f"{i}. {item['kitap_adi']} - {item['fiyat']} TL")
            return "\n".join(mesajlar)
    
    # Sepeti tamamen temizle
    def delete_cart(self):
        self.cart.clear()
        return "ğŸ§¹ Sepet temizlendi."
        return True  # (not: bu satÄ±ra asla ulaÅŸÄ±lamaz)

    # Sepetteki kitaplarÄ±n toplam fiyatÄ±nÄ± dÃ¶ndÃ¼r
    def total_cost(self):
        toplam = sum(item["fiyat"] for item in self.cart)
        return f"ğŸ’° Toplam Tutar: {toplam} TL"
        return True  # (not: bu satÄ±ra da ulaÅŸÄ±lamaz)


    # KullanÄ±cÄ±dan gelen prompta cevap Ã¼ret
    def prompt(self, query):
        # LLM zincirini oluÅŸtur
        question_answer_chain = create_stuff_documents_chain(self.llm, self.prompt_template)
        rag_chain = create_retrieval_chain(self.retriever, question_answer_chain)

        # Zinciri Ã§alÄ±ÅŸtÄ±r ve yanÄ±t al
        response = rag_chain.invoke({"input": query})
        answer = response["answer"]

        # Sepetle ilgili bir iÅŸlem olup olmadÄ±ÄŸÄ±nÄ± kontrol et
        intents = ["kitap_ekle", "sepet_goster", "sepet_temizle", "sepet_toplam", "kitap_cikar"]
        if any(k in answer.lower() for k in intents):
            parts = answer.split("-")
            intent = ""
            book = "" 
            if len(parts) == 2:
                intent, book = parts
            else:
                intent = answer
            
            # Ä°lgili sepet fonksiyonunu Ã§alÄ±ÅŸtÄ±r
            if intent == "kitap_ekle":
                return self.add_book(book)
            elif intent == "kitap_cikar":
                return self.delete_book(book)
            elif intent == "sepet_goster":
                return self.show_cart()
            elif intent == "sepet_temizle":
                return self.delete_cart()
            elif intent == "sepet_toplam":
                return self.total_cost()
        else:
            # Normal yanÄ±t dÃ¶ndÃ¼r
            return answer
